{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwVZqH2EN0nB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion extraction using Speechbrain\n",
        "This Python notebook is designed to extract emotion scores [Neutral, Happy, Sad, Angry] from WAV files using a pretrained SpeechBrain model. The extraction process relies on the time boundaries of voice transcriptions for each phrase. In this approach, phrases are analyzed at the phrase level, where the emotion scores are averaged for each emotion within the same chunk. This differs from the frame-level approach, where the scores are used as they are without averaging."
      ],
      "metadata": {
        "id": "0ilbPWl6npQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruQBV0vzN4AY",
        "outputId": "750374a4-aae7-4d92-9e57-9d4f638907e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tkt39BGoOLgs"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/CS5647 Sound/CS5647_Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJJbYHj_OrHh",
        "outputId": "7ca973be-7215-40ba-e032-7520a1e93fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2024.8.30)\n",
            "Downloading speechbrain-1.0.2-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.12 speechbrain-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain torch torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442,
          "referenced_widgets": [
            "27fe9db502174496b3ccaa6bd7c299d9",
            "4532205136b0426b99ea5824e34381a5",
            "8308d000c1174e95a5928c8440ebd0ec",
            "908e52aa871c47d8b0bcee780aef029c",
            "6547db05e7744d56a7c83ca89f9651ef",
            "f54026c25e25476294e5031437e80382",
            "d2191786ba6e4fb8b32b323ee58c6413",
            "cd7d3cdc69434f3aaf50b0d0f6352a23",
            "abae05e162994d748c6e3fc565a05879",
            "606d2aeec9b84da8b188a97acad3deb9",
            "1a03fc0dbba9407988c9ad5a10cb434a"
          ]
        },
        "id": "63kUsAxEOeUE",
        "outputId": "7d37258b-0c42-42d5-bd22-a5bc42851c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:306: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n",
            "/usr/local/lib/python3.10/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'402',\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/380M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27fe9db502174496b3ccaa6bd7c299d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'401',\n",
            "'400',\n",
            "'403',\n",
            "'414',\n",
            "'438',\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370: UserWarning: cuDNN cannot be used for large non-batch-splittable convolutions if the V8 API is not enabled or before cuDNN version 9.3+. Consider upgrading cuDNN and/or enabling the V8 API for better efficiency. (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:430.)\n",
            "  return F.conv1d(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'617',\n",
            "'618',\n",
            "'612',\n",
            "'615',\n",
            "'619',\n",
            "'620',\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Need to initialize the pretrained model first\n",
        "from speechbrain.pretrained import EncoderASR, EncoderClassifier\n",
        "import torchaudio\n",
        "import torch\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "# Load ASR and Emotion models from SpeechBrain\n",
        "# For asr-crdnn-rnnlm-librispeech, use this alternative\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model_asr = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "emotion_model = EncoderClassifier.from_hparams(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", savedir=\"./pretrained_emotion\")\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "\n",
        "\n",
        "# Loop through all wav files in the specified directory\n",
        "for audio_file in glob.glob(path + \"data/DAIC_WOZ/wavNscript/*.wav\"):\n",
        "    file_number = audio_file.split('/')[-1].split('_')[0]\n",
        "    if file_number in ['300','301','302','303','304','305','306',      '308','309','310','311','312','313','314','315','316','317','318','319',\n",
        "                       '320','321','322','323','324','325','326','327','328','329','330','331','332','333','334','335','336','337','338','339',\n",
        "                       '340','341',      '343','344','345','346','347','348','349','350','351','352','353','354','355','356','357','358','359',\n",
        "                       '360','361','362','363','364','365','366','367','368','369','370','371','372','373','374','375','376','377','378','379',\n",
        "                       '380','381','382','383','384','385','386','387','388','389','390','391','392','393',      '395','396','397',      '399',\n",
        "                       '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '415', '416', '417', '418', '419', '420', '421',\n",
        "                       '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437',' 438',\n",
        "                       '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455',\n",
        "                       '456', '457', '458', '459', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473',\n",
        "                       '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '485', '484', '486', '487', '488', '489', '490',\n",
        "                       '491', '492', '600', '601', '602', '605', '604', '606', '607',\n",
        "                       '603', '608', '609', '307', # Causing error in emotion extraciton\n",
        "                       '400','401','402','403','414','438','612','615','617','618','619' # on going results -> not included in project report\n",
        "                       ]:\n",
        "        continue\n",
        "\n",
        "    # print(f\"Processing file: {audio_file}\")\n",
        "    print(f\"'{file_number}',\")\n",
        "\n",
        "    # Extract the file number from the audio file path\n",
        "    transcript_file = path + f\"data/DAIC_WOZ/wavNscript/{file_number}_Transcript.csv\"\n",
        "    # print(f\"    with: {transcript_file}\")\n",
        "\n",
        "    # Step 1: Transcribe the audio using ASR (if needed) - we can keep this out of the loop if don't want to transcribe all audios again\n",
        "    try:\n",
        "        df_transcription = pd.read_csv(transcript_file)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Transcript file not found for {audio_file}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Step 2: Extract raw audio and run emotion detection\n",
        "    waveform, sample_rate = torchaudio.load(audio_file)\n",
        "    features = emotion_model.mods.wav2vec2(waveform)\n",
        "    emotion_scores = emotion_model.mods.output_mlp(features)\n",
        "\n",
        "\n",
        "    # Step 3: Perform sliding-window emotion detection\n",
        "    window_size = 1.0  # Sliding window size in seconds\n",
        "    step_size = 0.5  # Overlap step size\n",
        "    emotion_results = []\n",
        "\n",
        "    for i in range(0, waveform.shape[-1], int(step_size * sample_rate)):\n",
        "        window = waveform[:, i:i + int(window_size * sample_rate)]\n",
        "        if window.shape[-1] < window_size * sample_rate:\n",
        "            break  # Stop if the window size is smaller than required\n",
        "\n",
        "        score = emotion_model.mods.output_mlp(emotion_model.mods.wav2vec2(window))\n",
        "        emotion_results.append(score[0])\n",
        "\n",
        "    # Step 4: Align emotion predictions with phrase timestamps\n",
        "    phrase_emotion_scores = []\n",
        "    for index, row in df_transcription.iterrows():\n",
        "\n",
        "        start_time = row['Start_Time']\n",
        "        end_time = row['End_Time']\n",
        "        confidence = row['Confidence']\n",
        "        transcription = row['Text']\n",
        "\n",
        "        # Find corresponding emotion scores within the phrase's time range\n",
        "        emotions_for_phrase = [e for (j, e) in enumerate(emotion_results)\n",
        "                            if j * step_size >= start_time and j * step_size <= end_time]\n",
        "\n",
        "        # Average the emotion scores across the window for that word\n",
        "        if len(emotions_for_phrase) >0:\n",
        "            avg_emotion_score = torch.mean(torch.stack(emotions_for_phrase), dim=0).tolist()\n",
        "        else:\n",
        "            avg_emotion_score = [[0.0, 0.0, 0.0, 0.0]]\n",
        "        phrase_emotion_scores.append({\n",
        "            \"phrase\": transcription,\n",
        "            \"emotion_score\": avg_emotion_score  # List of emotion probabilities\n",
        "        })\n",
        "\n",
        "\n",
        "    # Create/open the CSV file in append mode\n",
        "    emo_file = path + f\"data/DAIC_WOZ/wavNscript/{file_number}_phrase_emotions.csv\"\n",
        "    with open(emo_file, 'a', newline='') as csvfile:\n",
        "        fieldnames = ['phrase', 'emotion_score']  # Define column headers\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        # Write the header if the file is newly created (check file size)\n",
        "\n",
        "        if os.stat(emo_file).st_size == 0:\n",
        "            writer.writeheader()\n",
        "        # Write the phrase_emotion_scores to the CSV file\n",
        "        writer.writerow({'phrase': audio_file, 'emotion_score': []})\n",
        "        for item in phrase_emotion_scores:\n",
        "            writer.writerow(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zndZjMuf2SyS",
        "outputId": "f975c969-b57c-4a66-ee2d-256bad868104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "{'phrase': 'good', 'emotion_score': [[6.7289509773254395, -14.300140380859375, -2.990981101989746, 5.504098892211914], [6.754121780395508, -14.435650825500488, -2.8771352767944336, 5.355656623840332], [6.734217166900635, -14.400794982910156, -2.673593759536743, 5.264455795288086], [6.832696437835693, -14.580904006958008, -2.3428032398223877, 4.996855735778809], [6.903836727142334, -14.529321670532227, -2.4742608070373535, 5.091804027557373], [6.8349738121032715, -14.507585525512695, -2.5069408416748047, 5.120858192443848], [6.741348743438721, -14.524739265441895, -2.3476338386535645, 5.091528415679932], [6.822110176086426, -14.655706405639648, -2.362755298614502, 5.028277397155762], [6.821504592895508, -14.633331298828125, -2.3437819480895996, 5.059662818908691], [6.7699127197265625, -14.569358825683594, -2.397566795349121, 5.142264366149902], [6.753446578979492, -14.49173641204834, -2.4931397438049316, 5.203610897064209], [6.694135665893555, -14.517919540405273, -2.59428334236145, 5.3186211585998535], [6.634930610656738, -14.513773918151855, -2.6939260959625244, 5.392383575439453], [6.639169216156006, -14.519391059875488, -2.7124948501586914, 5.336417198181152], [6.563675880432129, -14.420164108276367, -2.7342631816864014, 5.4413018226623535], [6.642125606536865, -14.416451454162598, -2.6977944374084473, 5.336345672607422], [6.784439563751221, -14.556344985961914, -2.8039188385009766, 5.374162673950195], [6.783090114593506, -14.499532699584961, -2.830226182937622, 5.354268550872803], [6.699507713317871, -14.416234970092773, -2.7553296089172363, 5.43034553527832], [6.774215221405029, -14.495704650878906, -2.8038270473480225, 5.399118423461914], [6.850854873657227, -14.620378494262695, -2.6269850730895996, 5.249104022979736], [6.887737274169922, -14.584539413452148, -2.485346794128418, 5.124597549438477], [6.836853981018066, -14.5912446975708, -2.6036882400512695, 5.161299228668213], [6.810891151428223, -14.488164901733398, -2.7830963134765625, 5.3068318367004395], [6.901218414306641, -14.445856094360352, -3.157644033432007, 5.4589457511901855], [6.820493698120117, -14.367571830749512, -3.2148590087890625, 5.613136291503906], [6.945532321929932, -14.405799865722656, -3.314656972885132, 5.60268497467041], [6.959390163421631, -14.501111030578613, -3.2011325359344482, 5.506147861480713], [6.63176155090332, -14.19405746459961, -3.0891175270080566, 5.770278453826904], [6.868500709533691, -14.210638046264648, -3.1536378860473633, 5.662642478942871], [6.829444885253906, -14.112741470336914, -3.198460102081299, 5.785111427307129], [6.9667887687683105, -14.202075958251953, -3.479764699935913, 5.8460283279418945], [6.871519565582275, -14.053577423095703, -3.7067251205444336, 6.061212539672852], [7.145112991333008, -14.070690155029297, -3.5387189388275146, 5.662232875823975], [6.955996990203857, -13.573783874511719, -3.8054685592651367, 5.944342136383057], [7.044450759887695, -13.517589569091797, -3.803215980529785, 5.761434555053711], [6.8945817947387695, -13.322744369506836, -3.7514114379882812, 6.001959323883057], [6.894131183624268, -13.224359512329102, -3.9577255249023438, 5.979568004608154], [7.09617280960083, -13.238241195678711, -3.8797497749328613, 5.650385856628418], [7.077269554138184, -13.092655181884766, -4.164617538452148, 5.964290618896484], [7.057005405426025, -13.032428741455078, -4.050723552703857, 5.8848772048950195], [6.975975513458252, -12.906208038330078, -3.9806318283081055, 5.903011322021484], [6.9488067626953125, -12.905881881713867, -4.056707382202148, 6.0150465965271], [7.017175674438477, -12.867422103881836, -4.150684356689453, 6.017686367034912], [6.927679061889648, -12.818679809570312, -4.1891374588012695, 6.075292110443115], [7.036393165588379, -12.769786834716797, -4.198119163513184, 6.021807670593262], [7.123576641082764, -12.813125610351562, -4.189504146575928, 5.954636573791504], [7.02458381652832, -12.792715072631836, -4.200616359710693, 6.01381254196167], [6.9305267333984375, -12.647367477416992, -4.256412029266357, 6.173928260803223], [7.036760330200195, -12.636822700500488, -4.1449689865112305, 5.993418216705322], [7.064311981201172, -12.683478355407715, -4.191141128540039, 6.0460028648376465], [7.095150470733643, -12.68110466003418, -4.089310646057129, 5.866739273071289], [7.081469535827637, -12.671658515930176, -4.088931560516357, 5.973001003265381], [7.072072982788086, -12.693604469299316, -4.223054885864258, 6.068335056304932], [7.020744323730469, -12.63729476928711, -4.368925094604492, 6.209125995635986], [7.020163536071777, -12.703533172607422, -4.316675186157227, 6.13200044631958], [7.00473690032959, -12.649707794189453, -4.16664457321167, 5.998692512512207], [7.026455879211426, -12.566280364990234, -4.159046173095703, 6.06458044052124], [7.010634422302246, -12.79082202911377, -4.031476020812988, 5.897437572479248], [7.0730791091918945, -12.843245506286621, -4.032411098480225, 5.808284759521484], [7.052799224853516, -12.753337860107422, -3.9965224266052246, 5.8725056648254395], [7.112192153930664, -12.669299125671387, -4.145155906677246, 5.962272644042969], [7.009284019470215, -12.700971603393555, -4.2492780685424805, 6.179403305053711], [7.011407375335693, -12.597938537597656, -4.1343584060668945, 6.063390731811523], [7.032073020935059, -12.636897087097168, -4.151876449584961, 5.980751037597656], [7.091213703155518, -12.596988677978516, -4.22031831741333, 6.095897674560547], [7.028753280639648, -12.685098648071289, -4.209414482116699, 6.010212421417236], [7.168612003326416, -12.685908317565918, -4.229588508605957, 5.870556354522705], [7.032967567443848, -12.549249649047852, -4.253894329071045, 6.002981185913086], [6.988739967346191, -12.558856964111328, -4.334680080413818, 6.119238376617432], [7.087563514709473, -12.6392822265625, -4.275799751281738, 6.011255264282227], [7.070730209350586, -12.594145774841309, -4.297133922576904, 6.014756679534912], [7.0139689445495605, -12.539880752563477, -4.302968978881836, 6.16849422454834], [7.062897682189941, -12.554773330688477, -4.344042778015137, 6.121095180511475], [7.080048561096191, -12.5894193649292, -4.378861427307129, 6.161872386932373], [7.038236618041992, -12.582293510437012, -4.260698318481445, 6.014561176300049], [7.0436859130859375, -12.602030754089355, -4.365171432495117, 6.1527934074401855], [7.1464762687683105, -12.670607566833496, -4.337703227996826, 5.999490737915039], [7.164975643157959, -12.634248733520508, -4.31743049621582, 6.027126312255859], [7.181641578674316, -12.610616683959961, -4.385145664215088, 6.0878472328186035], [7.12143611907959, -12.622854232788086, -4.302478790283203, 6.118395805358887], [7.130651473999023, -12.561014175415039, -4.438920974731445, 6.1699395179748535], [7.092437744140625, -12.651697158813477, -4.327883243560791, 6.05560827255249], [7.10863733291626, -12.577415466308594, -4.347629547119141, 6.0267205238342285], [7.026671409606934, -12.633893013000488, -4.276671409606934, 6.171003818511963], [7.060364723205566, -12.653059959411621, -4.517669200897217, 6.316397190093994], [7.091936111450195, -12.61674976348877, -4.3864545822143555, 6.140936374664307], [7.124703884124756, -12.599933624267578, -4.446722030639648, 6.154052734375], [7.068422317504883, -12.616040229797363, -4.390691757202148, 6.179600715637207], [7.117973327636719, -12.63967514038086, -4.418078899383545, 6.157882213592529], [7.108137607574463, -12.612374305725098, -4.27356481552124, 6.047529697418213], [7.11947774887085, -12.701866149902344, -4.320245742797852, 5.9953083992004395], [7.111055850982666, -12.613710403442383, -4.348456859588623, 6.056234359741211], [7.149215221405029, -12.631355285644531, -4.416804790496826, 6.151226043701172], [7.074187755584717, -12.65672492980957, -4.338272571563721, 6.180118083953857], [7.029888153076172, -12.651764869689941, -4.382018566131592, 6.227744102478027], [7.074330806732178, -12.613417625427246, -4.4433112144470215, 6.18264627456665], [6.982021331787109, -12.554682731628418, -4.4234490394592285, 6.332597732543945], [7.174080848693848, -12.644220352172852, -4.351242542266846, 6.025262355804443], [7.067343235015869, -12.529987335205078, -4.339227676391602, 6.119418621063232], [7.006620407104492, -12.551179885864258, -4.333789825439453, 6.1542768478393555], [7.1424760818481445, -12.583996772766113, -4.409241199493408, 6.115403175354004], [7.127096176147461, -12.672065734863281, -4.421769618988037, 6.0085835456848145], [7.053501129150391, -12.56440544128418, -4.463927268981934, 6.220338344573975], [7.0520524978637695, -12.546247482299805, -4.415377616882324, 6.0980024337768555], [7.14513635635376, -12.68124008178711, -4.4569501876831055, 6.092869758605957], [7.105341911315918, -12.631616592407227, -4.313995838165283, 6.081509113311768], [7.039697647094727, -12.5321044921875, -4.3740644454956055, 6.0811686515808105], [7.060080528259277, -12.580059051513672, -4.465704917907715, 6.207185745239258], [7.059863567352295, -12.560112953186035, -4.456769943237305, 6.262710094451904], [7.102907180786133, -12.614494323730469, -4.457798004150391, 6.2648234367370605], [6.979741096496582, -12.691081047058105, -4.362412452697754, 6.226508617401123], [7.140896320343018, -12.681565284729004, -4.3181538581848145, 5.975237846374512], [7.078945159912109, -12.63336181640625, -4.411812782287598, 6.149482250213623], [7.106923580169678, -12.558395385742188, -4.410952568054199, 6.156699180603027], [7.088268756866455, -12.589478492736816, -4.25370979309082, 6.139507293701172], [7.135178089141846, -12.65095329284668, -4.150147914886475, 5.970973014831543], [7.08851432800293, -12.59251880645752, -4.36657190322876, 6.1211066246032715], [7.046422004699707, -12.548978805541992, -4.474817276000977, 6.242608070373535], [7.033117771148682, -12.626258850097656, -4.434478759765625, 6.202765464782715], [7.065963268280029, -12.575891494750977, -4.414648056030273, 6.248838424682617], [7.122901916503906, -12.585328102111816, -4.440651893615723, 6.12673282623291], [7.191633701324463, -12.599369049072266, -4.461879730224609, 6.033485412597656], [7.121647834777832, -12.53943920135498, -4.33939266204834, 6.099935531616211], [7.10695219039917, -12.636005401611328, -4.369105815887451, 6.1483964920043945], [7.060467720031738, -12.594380378723145, -4.332263946533203, 6.180052757263184], [7.051209926605225, -12.604199409484863, -4.398611545562744, 6.26922082901001], [7.0079264640808105, -12.676542282104492, -4.359158039093018, 6.109054088592529], [6.9973602294921875, -12.523069381713867, -4.465732574462891, 6.218684196472168], [7.092806816101074, -12.576519966125488, -4.422607421875, 6.037363529205322], [7.101797580718994, -12.532442092895508, -4.461298942565918, 6.189730167388916], [7.120992660522461, -12.654151916503906, -4.286334991455078, 6.146425724029541], [7.07177734375, -12.601593017578125, -4.29365873336792, 6.120512008666992], [7.115739822387695, -12.72021484375, -4.321995735168457, 6.104968070983887], [7.1117353439331055, -12.722330093383789, -4.248867988586426, 6.106142520904541], [7.116610527038574, -12.808321952819824, -4.259136199951172, 6.145230293273926], [7.188912868499756, -12.900075912475586, -4.271679878234863, 6.001385688781738]]}\n"
          ]
        }
      ],
      "source": [
        "print(len(phrase_emotion_scores))\n",
        "print(phrase_emotion_scores[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hDi2YE8OugoY",
        "outputId": "b1652efd-6af4-4db1-c080-2cc09fdfd1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "137\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[6.7289509773254395,\n",
              "  -14.300140380859375,\n",
              "  -2.990981101989746,\n",
              "  5.504098892211914],\n",
              " [6.754121780395508,\n",
              "  -14.435650825500488,\n",
              "  -2.8771352767944336,\n",
              "  5.355656623840332],\n",
              " [6.734217166900635,\n",
              "  -14.400794982910156,\n",
              "  -2.673593759536743,\n",
              "  5.264455795288086],\n",
              " [6.832696437835693,\n",
              "  -14.580904006958008,\n",
              "  -2.3428032398223877,\n",
              "  4.996855735778809],\n",
              " [6.903836727142334,\n",
              "  -14.529321670532227,\n",
              "  -2.4742608070373535,\n",
              "  5.091804027557373]]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(phrase_emotion_scores)\n",
        "# phrase_emotion_scores[0]\n",
        "print(len(phrase_emotion_scores[0]['emotion_score']))\n",
        "phrase_emotion_scores[0]['emotion_score'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0wrKcBkXSDr",
        "outputId": "4e1aed8d-2b70-40a1-dfb6-2a30751372f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 Neutral      Happy        Sad           Angry        \n",
            "                              so I'm going to [ 12.32447507 -12.07226545  -5.52684767   0.0738344 ]\n",
            "                         interview in Spanish [12.94128605 -9.95798156 -2.58876414 -5.71331066]\n",
            "                                         okay [16.55466889 -7.38492625 -7.81034679 -6.17315637]\n",
            "                                         good [16.56782271 -6.27761511 -8.68089255 -5.91080189]\n",
            "                              Atlanta Georgia [16.77601869 -8.16337349 -7.42987523 -5.99051741]\n",
            "                     my parents are from here [12.20556491 -9.395598   -2.12558469 -4.98088449]\n",
            "                                    I love it [15.64358655 -9.28779931 -8.0404845  -3.12641051]\n",
            "  I like the weather I like the opportunities [  5.44363773 -12.85527155   0.59646954   2.26757566]\n",
            "                                at the minute [15.96490138 -8.90930802 -7.46222741 -4.60714845]\n",
            "                                 someone easy [ 15.36241599 -10.2450037   -7.31801619  -2.92864886]\n",
            "                                   congestion [  7.42771199 -10.74574007   1.99568599  -3.38475016]\n",
            "                                    that's it [14.979225   -8.4374713  -8.12572982 -2.98382199]\n",
            "        I took up business and administration [ 10.26117625 -10.44907547   0.4649104   -5.06606278]\n",
            " yeah I am here and there I'm on a break right now but I plan on going back in the next semester [ 12.38877049 -10.22663611  -5.65996531  -0.98507011]\n",
            "          probably to open up my own business [16.97435936 -8.62072042 -6.21810541 -6.81511554]\n",
            "                                           no [15.96060833 -7.94566386 -7.90152386 -4.596461  ]\n",
            "                    no specific reason I just [ 15.59796907 -10.7451103   -7.07783144  -2.97949692]\n",
            "                                  once a year [12.97657344 -1.47676919 -6.54525792 -7.44860434]\n",
            "                    email a bit more specific [17.31541782 -6.88142654 -8.85338949 -5.91181614]\n",
            "                                    no answer [ 16.06789056 -10.97384628  -5.71791584  -4.89480166]\n",
            " I like reading books Behringer I enjoy cooking sizing is great [ 12.44820896 -11.5327737   -5.20741487  -0.71537109]\n",
            "                               probably about [17.13453484 -9.62845139 -7.52909105 -4.94402735]\n",
            "                                  2 weeks ago [ 15.54838221 -11.97844608  -5.1795679   -3.97605596]\n",
            "                            I don't like bias [10.34513512 -9.72291104 -1.93687314 -3.09802748]\n",
            "                                    from what [15.84891452 -9.37549305 -6.81226297 -4.5682167 ]\n",
            "                        I like to play sports [16.82131868 -8.3789711  -6.6913733  -6.41919352]\n",
            " I enjoy I'm going out with friends and family [ 11.08712375 -11.25211105  -1.92708986  -2.5897324 ]\n",
            "                                 flying games [ 12.30956784 -11.99562431  -2.82516746  -2.51593525]\n",
            "                                 grandparents [14.93428933 -9.23455795 -7.25556258 -3.25142287]\n",
            "                                      parents [15.39489084 -9.70852971 -7.30207065 -3.44006739]\n",
            " yeah I mean they've always gave me great advice [ 15.50845358 -10.5638366   -4.23967794  -5.9800694 ]\n",
            "                                rice Cafe Rio [  4.50017001 -13.20470238  -1.43835053   6.07299913]\n",
            "                                  spell Klaus [ 10.64373485 -12.01522973  -5.7276366    2.2972543 ]\n",
            "                         I would say going to [ 13.14183222 -10.83945278  -5.24545841  -1.91552821]\n",
            "                           Powell High School [ 11.05234169 -11.59845029  -5.64076131   1.48930586]\n",
            "  well I would have been done by now and then [ 10.77834474 -10.55300098  -2.3936636   -2.40224616]\n",
            " I would have probably been out in the field in the career field [ 15.04898809 -10.43975616  -7.28543927  -2.18002976]\n",
            "                taking the job off the street [11.66183322 -8.10590431 -2.07240378 -5.735928  ]\n",
            "                    I'm sure I could have yes [12.69122455 -9.35538323 -2.23825559 -5.87003702]\n",
            " I'm not sure I've been I graduated from high school [ 11.88634662 -11.05084696  -4.00535529  -1.53091478]\n",
            "                I'd love to hear all about it [ 8.02201509 -1.60113107 -2.05746165 -6.56518858]\n",
            "                        well I got my diploma [ 14.03826893 -10.55360954  -3.30610551  -5.39740814]\n",
            " I finished school and I have met all the requirements [ 16.46210324 -11.2779925   -5.62455926  -4.99654191]\n",
            "                                  High School [ 12.26532878 -11.44972811  -7.16496516   1.74467549]\n",
            "                    when I was approved to go [  1.34722073 -10.6326306   -6.05747986  12.96106381]\n",
            "                   do whatever I wanted to do [15.47497239 -9.44344445 -7.57702934 -3.28915636]\n",
            "                              living with who [ 13.36698057 -10.81433756  -6.59871909  -0.74624592]\n",
            "            it's all right it could be better [17.645288   -8.1886247  -7.64989529 -6.36271631]\n",
            "                                           no [ 10.30724601 -10.28191058  -6.66506542   2.66361839]\n",
            "                          so it's pretty easy [ -1.01048295  -3.52527454  13.29756859 -11.14986219]\n",
            "                                          yes [16.77624745 -9.35210588 -7.26536839 -5.34555238]\n",
            "                                  repeat that [16.8080419  -6.93796834 -8.45935148 -5.7870423 ]\n",
            "                                    irritated [ 15.04070521 -11.09207007  -3.99649004  -5.52889699]\n",
            "                                         lazy [ 15.75926456 -12.13902222  -4.75929456  -4.87562089]\n",
            "                                           no [ 14.14509257 -10.72241318  -6.60972686  -1.82606743]\n",
            "                                           no [16.65183091 -8.18039364 -8.33137423 -4.78069176]\n",
            "                                           no [16.28659922 -9.86473749 -7.68501097 -3.92521666]\n",
            "                                          now [14.89883732 -9.12389929 -7.61153664 -2.83001338]\n",
            "                                the other day [12.07866807 -7.29866063 -1.75978942 -6.87998625]\n",
            "           play there was a great son was out [17.07973963 -7.86790875 -7.91212773 -5.85001567]\n",
            "                                    different [16.05448752 -8.93470455 -7.93895139 -4.03655774]\n",
            "                                        laugh [ 13.1677012    1.01028208  -4.41302323 -11.79852951]\n",
            "                              less interested [14.52821177 -8.63057954 -5.02379843 -5.62646446]\n",
            "                                    shut down [  5.5734938    4.10339968   1.22522116 -11.18542817]\n",
            "                            about 2 weeks ago [13.46700024 -9.10507311 -2.93315638 -6.03099188]\n",
            " you know ya friend of mine was annoying me and I just [ 12.15836722 -12.74308539  -3.05250633  -1.1258607 ]\n",
            "                                 cut them off [14.38579361 -6.75277608 -7.2890365  -4.05602623]\n",
            "                             that's all right [ 15.66041092 -11.21491049  -5.2615797   -4.64153826]\n",
            "                                   friendship [15.75537894 -9.01588917 -8.21364984 -3.44244619]\n",
            "             how do your best friend describe [ 15.57628824 -10.51300459  -7.24734044  -3.12844822]\n",
            "                                    chocolate [ 11.72951167 -10.74506104  -0.16470096  -6.20834995]\n",
            "                                         tall [ 13.15980974 -12.63643171  -4.72661922  -1.1135549 ]\n",
            "                                         then [ 10.73985211 -11.95071306  -1.58238446  -1.94728998]\n",
            "                                    thank you [15.69879612 -9.36737113 -7.66971677 -3.77798636]\n",
            "                                      bye-bye [  7.13792266  -7.60766207   7.59425008 -11.78841054]\n",
            "   a real life person is really looking at me [17.52410643 -7.87850925 -7.51808724 -6.57563278]\n",
            "       cuz it looks exactly like she was like [ 13.76391142 -10.88124345  -5.86614632  -2.17679203]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(f\"{'':>45} {'   Neutral':<12} {'   Happy':<15} {       'Sad':<13} {'Angry':<12} \")\n",
        "for i in range(len(phrase_emotion_scores)):\n",
        "    emotion_array = np.array(phrase_emotion_scores[i]['emotion_score'])\n",
        "    phrase_emotion_scores[i]['avr_emo_score'] = emotion_array.mean(axis=0)\n",
        "\n",
        "    print(f\"{phrase_emotion_scores[i]['phrase']:>45} {phrase_emotion_scores[i]['avr_emo_score']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBvY2NrvxnLB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86FvHXq-CFeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcUad5dsCFhj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AEPx3HSCFku"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KS2cNvUCFny"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlRtjw_nCFqc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxnaZMnsCFtW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2oElxthCFwG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27fe9db502174496b3ccaa6bd7c299d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4532205136b0426b99ea5824e34381a5",
              "IPY_MODEL_8308d000c1174e95a5928c8440ebd0ec",
              "IPY_MODEL_908e52aa871c47d8b0bcee780aef029c"
            ],
            "layout": "IPY_MODEL_6547db05e7744d56a7c83ca89f9651ef"
          }
        },
        "4532205136b0426b99ea5824e34381a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54026c25e25476294e5031437e80382",
            "placeholder": "​",
            "style": "IPY_MODEL_d2191786ba6e4fb8b32b323ee58c6413",
            "value": "model.safetensors: 100%"
          }
        },
        "8308d000c1174e95a5928c8440ebd0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd7d3cdc69434f3aaf50b0d0f6352a23",
            "max": 380204696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abae05e162994d748c6e3fc565a05879",
            "value": 380204696
          }
        },
        "908e52aa871c47d8b0bcee780aef029c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_606d2aeec9b84da8b188a97acad3deb9",
            "placeholder": "​",
            "style": "IPY_MODEL_1a03fc0dbba9407988c9ad5a10cb434a",
            "value": " 380M/380M [00:02&lt;00:00, 251MB/s]"
          }
        },
        "6547db05e7744d56a7c83ca89f9651ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f54026c25e25476294e5031437e80382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2191786ba6e4fb8b32b323ee58c6413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd7d3cdc69434f3aaf50b0d0f6352a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abae05e162994d748c6e3fc565a05879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "606d2aeec9b84da8b188a97acad3deb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a03fc0dbba9407988c9ad5a10cb434a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}